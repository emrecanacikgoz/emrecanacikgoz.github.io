<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="Lorem ipsum"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CoALM</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="static/js/jquery.min.js"></script>
  <script src="static/js/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
  <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
  <style>
      /* #special-table tbody tr td:nth-child(0),
      #special-table tbody tr td:nth-child(1) {
          padding-right: 30px;
      }
      #special-table tbody tr td:nth-child(0),
      #special-table tbody tr td:nth-child(1) {
          padding-left: 30px;
      } */

      .number-box {
          border: 1px solid #000; /* ÈªëËâ≤ËæπÊ°Ü */
          padding: 3px; /* ÂÜÖËæπË∑ù */
          margin: 3px; /* Â§ñËæπË∑ù */
      }
  </style>

    
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <style>
                  .logo {
                    width: 1.5em; /* Ë∞ÉÊï¥ÂõæÊ†áÂ§ßÂ∞è */
                    position: relative; /* ‰Ωø top Âíå left Â±ûÊÄßÁîüÊïà */
                    top: -10px; /* Âêë‰∏äÁßªÂä® */
                    left: -5px; /* ÂêëÂ∑¶ÁßªÂä® */
                    vertical-align: middle;
                  }
                </style>
                
                Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><a href="https://emrecanacikgoz.github.io/" target="_blank">Emre Can Acikgoz</a><sup>1</sup>,</span>
              <span class="author-block"><a href="" target="_blank">Jeremiah Greer</a><sup>2</sup>,</span>
              <span class="author-block"><a href="" target="_blank">Akul Datta</a><sup>1</sup>,</span>
              <span class="author-block"><a href="" target="_blank">Ze Yang</a><sup>1</sup>,</span>
              <span class="author-block"><a href="" target="_blank">William Zeng</a><sup>2</sup>,</span><br>
              <span class="author-block"><a href="" target="_blank">Oussama Elachqar</a><sup>2</sup>,</span>
              <span class="author-block"><a href="" target="_blank">Emmanouil Koukoumidis</a><sup>2</sup>,</span>
              <span class="author-block"><a href="https://siebelschool.illinois.edu/about/people/faculty/dilek" target="_blank">Dilek Hakkani-Tur</a><sup>1</sup>,</span>
              <span class="author-block"><a href="https://siebelschool.illinois.edu/about/people/faculty/gokhan" target="_blank">Gokhan Tur</a><sup>1</sup></span>
            </div>

            <div class="is-size-5 publication-authors">
                <span class="author-block">
                University of Illinois Urbana-Champaign<sup>1</sup>,
                Oumi<sup>2</sup>,
            </div>

            <img alt="Conversational AI Lab" src="static/images/conv-oumi.png" style="width:10%" />

            <div class="is-size-5 publication-authors">
              <span class="author-block"><a href="https://uiuc-conversational-ai-lab.github.io/" target="_blank">ConvAI Lab</a> | <a href="https://github.com/oumi-ai/oumi" target="_blank">Oumi</a> <br></span>
              <!-- <span class="eql-cntrb"><small><br><sup>*</sup>Indicates Equal Contribution</small></span> -->
            </div> 

            <header style="text-align: center;">
            </header>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- Blog abstract Link -->
                      <span class="link-block">
                        <a href="https://emrecanacikgoz.github.io/Conversational-Agents/" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">üí°</span>
                          <span>Motivation Blog</span>
                        </a>
                      </span>


                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://arxiv.org/abs/2502.08820" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon"><i class="ai ai-arxiv"></i> </span>
                          <span>arXiv</span>
                        </a>
                      </span>

                      <!-- Huggingface link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/collections/uiuc-convai/calm-67a3da0baa69ae101e55699a" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">ü§ó</span>
                          <span>Models</span>
                      </a>
                    </span>

                      <span class="link-block">
                        <a href="https://huggingface.co/datasets/uiuc-convai/CALM-IT" target="_blank" class="external-link button is-normal is-rounded is-dark">
                            <span class="icon">ü§ó</span>
                            <span>Dataset</span>
                        </a>
                    </span>

                    <!-- Github link -->
                    <span class="link-block">
                      <a href="https://github.com/oumi-ai/oumi/tree/main/configs/projects/calm" target="_blank" class="external-link button is-normal is-rounded is-dark">
                        <span class="icon"><i class="fab fa-github"></i> </span>
                        <span>Code</span>
                      </a>
                    </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<header style="text-align: center;">
  <img src="static/images/fig1.png" alt="ResultsTable" width="70%" >
</header>
-->


<!-- Paper abstract -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Abstract</h2>
                  <div class="content has-text-justified">
                      <p>
                        Large Language Models (LLMs) with API-calling capabilities enabled building Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm.
                        However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of target APIs, requiring new data to maintain their quality when interfacing with new services, while LAs often struggle to maintain user intent over multi-turn conversations. 
                        Because both robust multi-turn management and advanced function calling are crucial for effective Conversational Agents, we evaluate these skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and API-Bank (LA)‚Äîand our analyses reveal that specialized approaches excel in one domain but underperform in the other.
                        To bridge this chasm, we introduce <strong>CoALM</strong> (<strong>Co</strong>nversational <strong>A</strong>gentic <strong>L</strong>anguage <strong>M</strong>odel), a unified approach that integrates both conversational and agentic capabilities.
                        We created <strong>CoALM-IT</strong>, a carefully constructed multi-task dataset that interleave multi-turn ReAct reasoning with complex API usage. Using CoALM-IT, we train three models <strong>CoALM-8B</strong>, <strong>CoALM-70B</strong>, and <strong>CoALM-405B</strong>, which outperform top domain-specific models, including GPT-4o, across all three benchmarks.
                        This demonstrates the feasibility of a single model approach for both TOD and LA, setting a new standard for Conversational Agents. We release all model weights, datasets, and training artifacts to support further research.
                      </p>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Why do we need CoALM? -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Why do we need CoALM?</h2>
                  <div class="content has-text-justified">
                   <!-- <img src="static/images/conv-new-new.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/> -->
                    <br>
                    <p> Imagine chatting with an AI that not only understands your every question across multiple turns but can also seamlessly call external services‚Äîlike booking a hotel, checking flight tickets, or retrieving product information‚Äîwhen needed. This vision has long been the holy grail of conversational AI, and the emergence of Large Language Models (LLMs) has brought us closer than ever. However, there remains a significant trade-off: traditional Task-Oriented Dialogue (TOD) systems excel at carefully orchestrated, multi-turn conversations but lack the adaptability to use new tools or APIs. Language Agents (LAs), on the other hand, can dynamically invoke APIs but often fumble through multi-turn scenarios, losing track of what the user really wants. Our paper tackles this dilemma head-on.</p>
                    <p>Our release includes:</p>
                        <ul style="list-style-type: disc; margin-left: 20px;">
                            <li> CoALM, a family of model series at different scales <a href="https://huggingface.co/uiuc-convai/CALM-8B">CoALM 8B</a>, <a href="https://huggingface.co/uiuc-convai/CALM-70B">CoALM 70B</a> and the largest open-source conversational agent <a href="https://huggingface.co/uiuc-convai/CALM-405B">CoALM 405B</a>‚Äîall unified by unified multi-turn dialogue skills and advanced function-calling capabilities. Our larger models, CoALM 70B and CoALM 405B, outperform GPT-4o and GPT-4o-mini on both TOD and LA tasks, narrowing the gap between closed-source and open-source models. </li>
                            <li> We introduce <a href="https://huggingface.co/datasets/uiuc-convai/CALM-IT">CoALM-IT</a>, a hybrid dataset for conversational agents featuring unique ReAct reasoning steps in multi-turn settings, encompassing 312K samples across diverse domains, tasks, and abilities.</li>
                            <li> To foster further research within the open-source community, we publicly release all model weights, datasets, intermediate checkpoints, and wandb reports.</li>
                        </ul>
                    
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Hippo Series -->

<!-- Confronting the TOD vs. LA Dilemma -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Confronting the TOD vs. LA Dilemma</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/tod-la.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 85%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                        <li> TOD systems typically rely on domain-specific data and rigid pipelines. They can accomplish booking tasks well in a controlled setting (e.g., "reserve a table at 6 PM"), but adding a new service‚Äîsay, a flight API‚Äîrequires new training data or extensive manual modifications. LAs, powered by advanced LLMs, handle a broad range of APIs on the fly, yet they may go off track in longer dialogues: user intentions get muddled, or the conversation derails. As user demands expand beyond narrowly defined tasks, we need an agent that can juggle wide-ranging domains, maintain conversation flow, and call upon a varied set of tools without skipping a beat. <br>     
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Methodology -->

<!-- Introducing CoALM Framework -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Introducing CoALM Framework</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/calm.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 95%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                        <li><strong>CoALM.</strong> To bridge this gap, we propose CoALM (Conversational Agentic Language Model), a unified approach that combines the robust multi-turn dialogue management of TOD with the dynamic function-calling prowess of LAs. Drawing on diverse data sources, we interleave standard booking flows, open-ended dialogues, and complex function calls, all unified under the umbrella of a single system. The result is an agent that adapts to new services without exhaustive retraining, while also preserving the clarity of multi-turn user interactions.<br> <br>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Stages <style>.logo1 {vertical-align: middle;}</style>-->

<!-- Introducing CALM Framework -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">CoALM-IT Dataset</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/table.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 95%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                        <li><strong>CoALM-IT.</strong> At the heart of CoALM is our CoALM-IT dataset‚Äîa carefully constructed multi-task corpus that blends state-tracking tasks, comprehensive TOD dialogues, and ReAct-based function usage. We apply this dataset to train models of various scales: <strong>CoALM-8B</strong>, <strong>CoALM-70B</strong>, and <strong>CoALM-405B</strong>. Unlike most TOD datasets that focus on a limited set of actions, CoALM-IT introduces scenarios where the AI must pick and choose from an array of potential APIs, reason out the user‚Äôs need (sometimes over multiple turns), and decide how best to respond. By consistently interleaving standard dialogue tasks with tool-calling scenarios, we foster a system that simultaneously learns to maintain context and interact with external services.
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Stages <style>.logo1 {vertical-align: middle;}</style>-->

<!-- Uncertainty Quantification -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Results</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/results2.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 95%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                      <li><strong>Results on MultiWOZ.</strong> we compare CoALM against specialized approaches and baseline LLMs. Traditional dialogue systems outperformed LAs on MultiWOZ‚Äôs core metrics like Inform Rate and Success Rate‚Äîoften surpassing 40‚Äì50% success when well-trained. But LAs with advanced API-calling capabilities saw their success rates plummet, sometimes below 20%, revealing their struggle to track user needs in multi-turn dialogues. In contrast, CoALM soared: even our smallest CoALM-8B model doubled the success rates of typical LAs, and our larger models rivaled or exceeded top proprietary solutions.<br> <br>
                      <li><strong>Results on BFCL and API-Bank.</strong> Next, we turn to two popular benchmarks for function calling: BFCL V3 and API-Bank. Here, specialized LAs shine, adeptly generating syntactically correct API calls with high success rates on short, single-turn prompts. When extended to multi-turn, they often stumble. Our results show how CoALM closes this gap. CoALM-8B significantly outperforms TOD-only models‚Äîrevealing that domain-restricted architectures can‚Äôt pivot to new tools. More impressively, our larger CoALM-70B and CoALM-405B not only handle unknown APIs but also maintain coherent conversations, besting strong baselines like GPT-4o on both TOD and tool-calling tasks in key metrics.
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Uncertainty Quantification -->

<!-- 
<section class="section" id="Conclusion">
  <div class="container is-max-desktop content">
      <h2 class="title">Conclusion</h2>
      <p>In this study, we have introduced Hippocrates, a comprehensive and open-source framework tailored for the medical domain, addressing a wide array of challenges faced by medical LLMs. We provide openly available datasets and establish an intuitive benchmark using the LM-Evaluation-Harness tool. We also introduce Hippo-M and Hippo-L , two 7B models demonstrating superior performance. Our work makes substantial contributions to the field by combining in-depth empirical research with a structured training methodology, offering invaluable insights and tools for future research not only in healthcare but in any area requiring domain-specific adaptation of LLMs</p>
  </div>
</section>
-->


<!-- Limitations -->

<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">The Path Forward</h2>
                  <div class="content has-text-justified">
                    <ul style="list-style-type: none;">
                        <li>By unifying TOD strengths and LA flexibility, we believe CoALM sets a new paradigm for Conversational Agents. Beyond the promising numbers, our open-source release of model weights, datasets, and training artifacts offers the community an unprecedented opportunity to explore and refine these capabilities further. Whether you‚Äôre looking to build a chat assistant that can manage a business meeting or an AI travel agent that can handle flight, hotel, and taxi bookings all in one conversation, CoALM blueprint is designed to adapt. We look forward to the innovations that researchers and developers will create, pushing us closer to a future where AI can truly converse, reason, and act in one unified frame.<br> <br>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Limitations -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
      <h2 class="title">License and BibTeX</h2>
      This model is licensed under <a href="https://creativecommons.org/licenses/by-nc/4.0/legalcode">Creative Commons NonCommercial (CC BY-NC 4.0)l</a><br>
      Please don't forget to kindly cite our paper if you use our models, data, codes, or results:
      <br><br>
      <pre><code>
        @misc{acikgoz2025singlemodelmastermultiturn,
          title={Can a Single Model Master Both Multi-turn Conversations and Tool Use? CoALM: A Unified Conversational Agentic Language Model}, 
          author={Emre Can Acikgoz and Jeremiah Greer and Akul Datta and Ze Yang and William Zeng and Oussama Elachqar and Emmanouil Koukoumidis and Dilek Hakkani-T√ºr and Gokhan Tur},
          year={2025},
          eprint={2502.08820},
          archivePrefix={arXiv},
          primaryClass={cs.AI},
          url={https://arxiv.org/abs/2502.08820}, 
    }
      </code></pre>
  </div>
</section>
<!--End BibTex citation -->

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgements</h2>
      We would like to acknowledge the Oumi AI team for their assistance in training and scaling with the larger CoALM models. We would also like to thank Together AI for providing the cluster resources necessary to enable CoALM-405B training. This project also has benefited from the Microsoft Accelerate Foundation
      Models Research (AFMR) grant program, through which leading foundation models hosted by Microsoft Azure and access to Azure credits were provided to conduct the research.. 
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
