<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  <!-- Meta tags for social media banners, these should be filled in appropriatly as they are your "business card" -->
  <!-- Replace the content tag with appropriate information -->
  <meta name="description" content="DESCRIPTION META TAG">
  <meta property="og:title" content="SOCIAL MEDIA TITLE TAG"/>
  <meta property="og:description" content="SOCIAL MEDIA DESCRIPTION TAG TAG"/>
  <meta property="og:url" content="Lorem ipsum"/>
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X630-->
  <meta property="og:image" content="static/image/your_banner_image.png" />
  <meta property="og:image:width" content="1200"/>
  <meta property="og:image:height" content="630"/>


  <meta name="twitter:title" content="TWITTER BANNER TITLE META TAG">
  <meta name="twitter:description" content="TWITTER BANNER DESCRIPTION META TAG">
  <!-- Path to banner image, should be in the path listed below. Optimal dimenssions are 1200X600-->
  <meta name="twitter:image" content="static/images/your_twitter_banner_image.png">
  <meta name="twitter:card" content="summary_large_image">
  <!-- Keywords for your paper to be indexed by-->
  <meta name="keywords" content="KEYWORDS SHOULD BE PLACED HERE">
  <meta name="viewport" content="width=device-width, initial-scale=1">


  <title>CALM</title>

  <link href="https://fonts.googleapis.com/css?family=Google+Sans|Noto+Sans|Castoro" rel="stylesheet">

  <link rel="stylesheet" href="static/css/bulma.min.css">
  <link rel="stylesheet" href="static/css/bulma-carousel.min.css">
  <link rel="stylesheet" href="static/css/bulma-slider.min.css">
  <link rel="stylesheet" href="static/css/fontawesome.all.min.css">
  <link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons@1/css/academicons.min.css">
  <link rel="stylesheet" href="static/css/index.css">

  <script src="static/js/jquery.min.js"></script>
  <script src="static/js/main.js"></script>
  <script defer src="static/js/fontawesome.all.min.js"></script>
  <script src="static/js/bulma-carousel.min.js"></script>
  <script src="static/js/bulma-slider.min.js"></script>
  <script src="static/js/index.js"></script>

  <link rel="stylesheet" type="text/css" href="static/css/jquery.dataTables.css">
  <script type="text/javascript" charset="utf8" src="static/js/jquery-3.5.1.js"></script>
  <script type="text/javascript" charset="utf8" src="static/js/jquery.dataTables.js"></script>
  <style>
      /* #special-table tbody tr td:nth-child(0),
      #special-table tbody tr td:nth-child(1) {
          padding-right: 30px;
      }
      #special-table tbody tr td:nth-child(0),
      #special-table tbody tr td:nth-child(1) {
          padding-left: 30px;
      } */

      .number-box {
          border: 1px solid #000; /* ÈªëËâ≤ËæπÊ°Ü */
          padding: 3px; /* ÂÜÖËæπË∑ù */
          margin: 3px; /* Â§ñËæπË∑ù */
      }
  </style>

    
</head>
<body>


  <section class="hero">
    <div class="hero-body">
      <div class="container is-max-desktop">
        <div class="columns is-centered">
          <div class="column has-text-centered">
            <h1 class="title is-1 publication-title">
              <style>
                  .logo {
                    width: 1.5em; /* Ë∞ÉÊï¥ÂõæÊ†áÂ§ßÂ∞è */
                    position: relative; /* ‰Ωø top Âíå left Â±ûÊÄßÁîüÊïà */
                    top: -10px; /* Âêë‰∏äÁßªÂä® */
                    left: -5px; /* ÂêëÂ∑¶ÁßªÂä® */
                    vertical-align: middle;
                  }
                </style>
                
                Can Dialogue Systems Be Agents, and Agents Be Conversational?<br>CALM: A Unified Conversational Agentic Language Model 
            </h1>
            <div class="is-size-5 publication-authors">
              <!-- Paper authors -->
              <span class="author-block"><sup>1</sup><a href="https://emrecanacikgoz.github.io/" target="_blank">Emre Can Acikgoz</a>,</span>
              <span class="author-block"><sup>2</sup><a href="" target="_blank">Jeremiah Greer</a>,</span>
              <span class="author-block"><sup>1</sup><a href="" target="_blank">Akul Datta</a>,</span>
              <span class="author-block"><sup>1</sup><a href="" target="_blank">Ze Yang</a>,</span>
              <span class="author-block"><sup>2</sup><a href="" target="_blank">Oussama Elachqar</a>,</span><br>
              <span class="author-block"><sup>2</sup><a href="" target="_blank">Emmanouil Koukoumidis</a>,</span>
              <span class="author-block"><sup>1</sup><a href="" target="_blank">Dilek Hakkani-Tur</a>,</span>
              <span class="author-block"><sup>1</sup><a href="" target="_blank">Gokhan Tur</a></span>
            </div>

            <div class="is-size-5 publication-authors">
                <span class="author-block">
                <sup>1</sup>University of Illinois Urbana-Champaign,
                <sup>2</sup>Oumi,
            </div>

            <div class="column has-text-centered">
              <span class="author-block">
                  <a href="mailto:acikgoz2@illinois.edu">acikgoz2@illinois.edu</a></span>
            </div>

            <header style="text-align: center;">
              <img src="static/images/hippo2.png" alt="ResultsTable" width="85%" >
            </header>

                  <div class="column has-text-centered">
                    <div class="publication-links">
                      <!-- ArXiv abstract Link -->
                      <span class="link-block">
                        <a href="https://github.com/emrecanacikgoz" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon"> <i class="ai ai-arxiv"></i> </span>
                          <span>arXiv</span>
                        </a>
                      </span>

                      <!-- Huggingface link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/emrecanacikgoz" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span class="icon">ü§ó</span>
                          <span>Models</span>
                      </a>
                    </span>

                      <span class="link-block">
                        <a href="https://huggingface.co/emrecanacikgoz" target="_blank" class="external-link button is-normal is-rounded is-dark">
                            <span class="icon"><i class="fas fa-database"></i></span>
                            <span>Dataset</span>
                        </a>
                    </span>

                    <!-- Github link -->
                    <span class="link-block">
                      <a href="https://huggingface.co/emrecanacikgoz" target="_blank" class="external-link button is-normal is-rounded is-dark">
                        <span class="icon"> <i class="fab fa-github"></i> </span>
                        <span>Code</span>
                      </a>
                    </span>

                    <!-- Wandb -->
                    <span class="link-block">
                      <a href="https://huggingface.co/emrecanacikgoz" target="_blank" class="external-link button is-normal is-rounded is-dark">
                          <span>Wandb</span>
                      </a>
                    </span>

            </div>
          </div>
        </div>
      </div>
    </div>
  </div>
</section>

<!-- 
<header style="text-align: center;">
  <img src="static/images/fig1.png" alt="ResultsTable" width="70%" >
</header>
-->


<!-- Paper abstract -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Abstract</h2>
                  <div class="content has-text-justified">
                      <p>
                        Large Language Models (LLMs) with API-calling capabilities enabled building Language Agents (LA), while also revolutionizing the conventional task-oriented dialogue (TOD) paradigm.
                        However, current approaches face a critical dilemma: TOD systems are often trained on a limited set of target APIs, requiring new data to maintain their quality when interfacing with new services, while LAs often struggle to maintain user intent over multi-turn conversations. 
                        Because both robust multi-turn management and advanced function calling are crucial for effective Conversational Agents, we evaluate these skills on three popular benchmarks: MultiWOZ 2.4 (TOD), BFCL V3 (LA), and API-Bank (LA)‚Äîand our analyses reveal that specialized approaches excel in one domain but underperform in the other.
                        To bridge this chasm, we introduce CALM (<strong>C</strong>onversational <strong>A</strong>gentic <strong>L</strong>anguage <strong>M</strong>odel), a unified approach that integrates both conversational and agentic capabilities.
                        We created CALM-IT, a carefully constructed multi-task dataset that interleave multi-turn ReAct reasoning with complex API usage. Using CALM-IT, we train three models CALM-8B, CALM-70B, and CALM-405, which outperform top domain-specific models, including GPT-4o, across all three benchmarks.
                        This demonstrates the feasibility of a single model approach for both TOD and LA, setting a new standard for Conversational Agents. We release all model weights, datasets, and training artifacts to support further research.
                      </p>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End paper abstract -->

<!-- Hippo Series -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">CALM</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/conv-new-new.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/>
                    <br>
                    <p> Imagine chatting with an AI that not only understands your every question across multiple turns but can also seamlessly call external services‚Äîlike booking a hotel, checking flight tickets, or retrieving product information‚Äîwhen needed. This vision has long been the holy grail of conversational AI, and the emergence of Large Language Models (LLMs) has brought us closer than ever. However, there remains a significant trade-off: traditional Task-Oriented Dialogue (TOD) systems excel at carefully orchestrated, multi-turn conversations but lack the adaptability to use new tools or APIs. Language Agents (LAs), on the other hand, can dynamically invoke APIs but often fumble through multi-turn scenarios, losing track of what the user really wants. Our paper tackles this dilemma head-on.</p>
                    <p>Our release includes:</p>
                        <ul style="list-style-type: disc; margin-left: 20px;">
                            <li> CALM, a family of model series at different scales CALM 8B, CALM 70B and the largest open-source conversational agent CALM-405B‚Äîall unified by unified multi-turn dialogue skills and advanced function-calling capabilities. Our larger models, CALM 70B and CALM 405B, outperform GPT-4o and GPT-4o-mini on both TOD and LA tasks, narrowing the gap between closed-source and open-source models. </li>
                            <li> We introduce CALM-IT, a hybrid dataset for conversational agents featuring unique ReAct reasoning steps in multi-turn settings, encompassing 312K samples across diverse domains, tasks, and abilities.</li>
                            <li> To foster further research within the open-source community, we publicly release all model weights, datasets, intermediate checkpoints, and wandb reports.</li>
                        </ul>
                    
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Hippo Series -->

<!-- Hippocrates Framework
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Hippocrates Framework</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/fig2.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 95%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                      <li>In this work, we provide full access to our framework, from the data sources to the training configurations and the reproducible evaluation protocols. We conduct a detailed empirical analysis to identify the impact of various design elements on LLM performance, leading to a domain-adapted framework that demonstrates superior performance on multiple medical benchmarks. Based on these insights, we develop a step-by-step guide for the efficient training of medical-LLMs. Our research efforts yield two advanced 7B parameter models, Hippo-Mistral and Hippo-LLaMA. As shown in first figure, our models not only outperform existing 7B and 13B models by a significant margin but also deliver results on par with, and in some cases exceeding, those of 70B models. We argue that the development of a broad, varied collection of open models is crucial for deepening our knowledge of language models and enhancing their applicability across various domains.</li>
                      <li>The figure above shows the evolution of medical LLM performances on the MedQA dataset. Our 7B Hippo-Mistral and Hippo-LLaMA models achieve 50.8% and 59.9% 5-shot accuracy, respectively. Hippo-Mistral outperforms all existing open models, including even those with 70B parameters.</li>
                    </ul> 
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
End Hippocrates Framework -->


<!-- Dataset 
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Datasets</h2>
                  <div class="content has-text-justified">
                    <ul style="list-style-type: none;">
                          <li><strong>Continued Pre-training Data.</strong> A key aspect of our methodology is the integration of specialized medical knowledge through an extensive pre-training corpus, assembled from three specialized datasets: Medical Guidelines, PMC-Patients, and PubMedQA-contexts. The Medical Guidelines dataset comprises clinical practice guidelines, is used for training Meditron models. The PMC-Patients dataset consists of patient summaries extracted from case reports within PubMed Central (PMC). Additionally, the PubMedQA-contexts dataset is constructed by extracting the context field of each sample in the training split of the benchmark PubMedQA. This extensive corpus, consisting of roughly 300M training tokens, forms the foundation of our models, ensuring their proficiency in navigating medical terminology and practices. We systematically assessed the impact of each dataset, both individually and in combination, to optimize our model's performance. <br>
                          <li><strong>General Instructions Data.</strong> This dataset aggregates more than 400K samples from nine different datasets, each derived from the instruction corpora of previous studies. By excluding data from the training or test splits of downstream QA benchmarks, we aim to minimize bias and improve the model's generalization capabilities across different reasoning tasks. A pre-processing protocol was employed to remove irrelevant noise such as superfluous words and web URLs, ensuring the data's quality and relevance.
                          <li><strong>Evaluation Instructions Data.</strong> This dataset was formed to examine the effects of including instruction samples directly from downstream tasks, a common practice in existing studies. Instruction-response pairs were crafted using the training splits of various benchmarks, following the templates established in Meditron. We conducted a series of experiments to assess the distinct influence of each split on each task, both individually and collectively.
                          <li><strong>Medical Preference Data.</strong> Constructing a preference dataset typically involves generating diverse responses to identical queries using LLMs, which are subsequently evaluated by human annotators to identify the most accurate response. This method, however, can become prohibitively expensive, both in terms of computation for generating responses and the financial and time investments required for manual annotation. To circumvent these issues, we leveraged the iCliniq-10k dataset, containing 10K authentic patient-doctor dialogues from icliniq.com. Each dialogue features a patient question accompanied by three different answers: one from an actual doctor, and the others from ChatGPT and ChatDoctor. We conducted a thorough preprocessing of this dataset to eliminate any irrelevant or extraneous information.
                          <li><strong>Medical RLAIF.</strong> To reduce annotation costs, we adopted the RLAIF methodology in the medical domain for the first time. Utilizing detailed prompts based on patient inquiries from the iCliniq-10k dataset, we used GPT4 to determine the optimal response based on predefined instructions. These instructions were derived from those used in qualitative assessments by medical professionals in Med-PaLM, with minor modifications. This annotation approach amounted to a cost of $120.
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
 End Dataset -->
 
<!-- Methodology -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Confronting the TOD vs. LA Dilemma</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/conv-la.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                        <li> TOD systems typically rely on domain-specific data and rigid pipelines. They can accomplish booking tasks well in a controlled setting (e.g., "reserve a table at 6 PM"), but adding a new service‚Äîsay, a flight API‚Äîrequires new training data or extensive manual modifications. LAs, powered by advanced LLMs, handle a broad range of APIs on the fly, yet they may go off track in longer dialogues: user intentions get muddled, or the conversation derails. As user demands expand beyond narrowly defined tasks, we need an agent that can juggle wide-ranging domains, maintain conversation flow, and call upon a varied set of tools without skipping a beat. <br>     
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Methodology -->

<!-- Stages -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Introducing CALM Framework</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/calm.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                        <li><strong>CALM.</strong> To bridge this gap, we propose CALM (Conversational Agentic Language Model), a unified approach that combines the robust multi-turn dialogue management of TOD with the dynamic function-calling prowess of LAs. Drawing on diverse data sources, we interleave standard booking flows, open-ended dialogues, and complex function calls, all unified under the umbrella of a single system. The result is an agent that adapts to new services without exhaustive retraining, while also preserving the clarity of multi-turn user interactions.<br> <br>
                        <li><strong>CALM-IT.</strong> At the heart of CALM is our CALM-IT dataset‚Äîa carefully constructed multi-task corpus that blends state-tracking tasks, comprehensive TOD dialogues, and ReAct-based function usage. We apply this dataset to train models of various scales: <strong>CALM-8B</strong>, <strong>CALM-70B</strong>, and <strong>CALM-405B</strong>. Unlike most TOD datasets that focus on a limited set of actions, CALM-IT introduces scenarios where the AI must pick and choose from an array of potential APIs, reason out the user‚Äôs need (sometimes over multiple turns), and decide how best to respond. By consistently interleaving standard dialogue tasks with tool-calling scenarios, we foster a system that simultaneously learns to maintain context and interact with external services.
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Stages <style>.logo1 {vertical-align: middle;}</style>-->

<!-- Uncertainty Quantification -->
<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">Results</h2>
                  <div class="content has-text-justified">
                    <img src="static/images/res-bar.png" class="interpolation-image" alt="" style="display: block; margin-left: auto; margin-right: auto; width: 75%;"/>
                    <br>
                    <ul style="list-style-type: none;">
                      <li><strong>Results on MultiWOZ.</strong> we compare CALM against specialized approaches and baseline LLMs. Traditional dialogue systems outperformed LAs on MultiWOZ‚Äôs core metrics like Inform Rate and Success Rate‚Äîoften surpassing 40‚Äì50% success when well-trained. But LAs with advanced API-calling capabilities saw their success rates plummet, sometimes below 20%, revealing their struggle to track user needs in multi-turn dialogues. In contrast, CALM soared: even our smallest CALM-8B model doubled the success rates of typical LAs, and our larger models rivaled or exceeded top proprietary solutions.<br> <br>
                      <li><strong>Results on BFCL and API-Bank.</strong> Next, we turn to two popular benchmarks for function calling: BFCL V3 and API-Bank. Here, specialized LAs shine, adeptly generating syntactically correct API calls with high success rates on short, single-turn prompts. When extended to multi-turn, they often stumble. Our results show how CALM closes this gap. CALM-8B significantly outperforms TOD-only models‚Äîrevealing that domain-restricted architectures can‚Äôt pivot to new tools. More impressively, our larger CALM-70B and CALM-405B not only handle unknown APIs but also maintain coherent conversations, besting strong baselines like GPT-4o on both TOD and tool-calling tasks in key metrics.
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Uncertainty Quantification -->

<!-- 
<section class="section" id="Conclusion">
  <div class="container is-max-desktop content">
      <h2 class="title">Conclusion</h2>
      <p>In this study, we have introduced Hippocrates, a comprehensive and open-source framework tailored for the medical domain, addressing a wide array of challenges faced by medical LLMs. We provide openly available datasets and establish an intuitive benchmark using the LM-Evaluation-Harness tool. We also introduce Hippo-M and Hippo-L , two 7B models demonstrating superior performance. Our work makes substantial contributions to the field by combining in-depth empirical research with a structured training methodology, offering invaluable insights and tools for future research not only in healthcare but in any area requiring domain-specific adaptation of LLMs</p>
  </div>
</section>
-->


<!-- Limitations -->

<section class="hero">
  <div class="hero-body">
      <div class="container is-max-desktop">
          <div class="columns is-centered">
              <div class="column has-text-centered">
                  <h2 class="title is-3">The Path Forward</h2>
                  <div class="content has-text-justified">
                    <ul style="list-style-type: none;">
                        <li>By unifying TOD strengths and LA flexibility, we believe CALM sets a new paradigm for Conversational Agents. Beyond the promising numbers, our open-source release of model weights, datasets, and training artifacts offers the community an unprecedented opportunity to explore and refine these capabilities further. Whether you‚Äôre looking to build a chat assistant that can manage a business meeting or an AI travel agent that can handle flight, hotel, and taxi bookings all in one conversation, CALM‚Äôs blueprint is designed to adapt. We look forward to the innovations that researchers and developers will create, pushing us closer to a future where AI can truly converse, reason, and act in one unified frame.<br> <br>
                  </div>
              </div>
          </div>
      </div>
  </div>
</section>
<!-- End Limitations -->


<!--BibTex citation -->
<section class="section" id="BibTeX">
  <div class="container is-max-desktop content">
      <h2 class="title">BibTeX</h2>
      Please don't forget to kindly cite our paper if you use our models, data, codes, or results:
      <br><br>
      <pre><code>
        @misc{TODO
        }
      </code></pre>
  </div>
</section>
<!--End BibTex citation -->

<section class="section" id="Acknowledgements">
  <div class="container is-max-desktop content">
      <h2 class="title">Acknowledgements</h2>
      This work is supported in part provided by the UIUC and Oumi. 
  </div>
</section>


  <footer class="footer">
  <div class="container">
    <div class="columns is-centered">
      <div class="column is-8">
        <div class="content">

          <p>
            This page was built using the <a href="https://github.com/eliahuhorwitz/Academic-project-page-template" target="_blank">Academic Project Page Template</a> which was adopted from the¬†<a href="https://nerfies.github.io" target="_blank">Nerfies</a>¬†project page.
            You are free to borrow the of this website, we just ask that you link back to this page in the footer. <br> This website is licensed under a <a rel="license"  href="http://creativecommons.org/licenses/by-sa/4.0/" target="_blank">Creative
            Commons Attribution-ShareAlike 4.0 International License</a>.
          </p>

        </div>
      </div>
    </div>
  </div>
</footer>

<!-- Statcounter tracking code -->
  
<!-- You can add a tracker to track page visits by creating an account at statcounter.com -->

    <!-- End of Statcounter Code -->

  </body>
  </html>
